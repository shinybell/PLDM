import argparse
import yaml

import numpy as np
import torch
from tqdm import tqdm

from pldm_envs.wall.data.wall import WallDataset, WallDatasetConfig
from pldm_envs.wall.save_wall_ds import update_config_from_yaml


def parse_args():
    """A function to parse arguments with argparse:
    - data_paths: a list of paths to the data files
    - wc_rate: target wall crossing rate in the new dataset
    - output_path: path to save the new dataset
    """

    parser = argparse.ArgumentParser(
        description="Render images in a dataset without image observations",
    )
    parser.add_argument("--input_path", type=str, help="Path to the data file")
    parser.add_argument("--config", type=str, help="Path to the dataset config file")
    parser.add_argument(
        "--output_path",
        type=str,
        default="new_dataset.npz",
        help="Path to save the new dataset with images rendered.",
    )
    parser.add_argument(
        "--render_batch_size",
        type=int,
        default=1000,
        help="Number of trajectories render at a time",
    )

    return parser.parse_args()


def main():
    args = parse_args()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ãƒãƒƒãƒ—ã§èª­ã¿è¾¼ã‚€ (ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ç¶­æŒ)
    # data_mmap ã¯è¾æ›¸ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã„ã¾ã™ãŒã€å·¨å¤§ãªé…åˆ—ã¯ç‰©ç†ãƒ¡ãƒ¢ãƒªã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã€‚
    data_mmap = np.load(args.input_path, mmap_mode="r") 
    locations = data_mmap["locations"] 
    num_locations = len(locations)

    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ç·ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {num_locations}")

    # 1. Configã®èª­ã¿è¾¼ã¿ã¨WallDatasetã®åˆæœŸåŒ–
    try:
        with open(args.config, "r") as file:
            yaml_config = yaml.safe_load(file)
    except FileNotFoundError:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.config}")
        return
        
    config = update_config_from_yaml(WallDatasetConfig, yaml_config)
    ds = WallDataset(config)
    H, W = config.img_size, config.img_size 

    # 2. Wallæƒ…å ±ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¦ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã«æ ¼ç´
    wall_info = ds.sample_walls()
    walls_tensor = ds.render_walls(*wall_info)
    # æœ€åˆã®å£ã®ã¿ã‚’ä½¿ç”¨ã—ã€NumPyé…åˆ— (H, W, 1) ã«å¤‰æ›
    walls_numpy = walls_tensor[0].unsqueeze(-1).numpy() 
    print(f"ğŸ–¼ï¸ Wallæƒ…å ±ãŒãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚Œã¾ã—ãŸã€‚å½¢çŠ¶: {walls_numpy.shape}")

    # 3. ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹æœ€çµ‚çš„ãªè¾æ›¸ã‚’åˆæœŸåŒ–
    final_data = {}
    
    # locationsä»¥å¤–ã®ã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼ (é€šå¸¸ã¯ã‚µã‚¤ã‚ºãŒå°ã•ã„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)
    for key, value in data_mmap.items():
        if key != "locations":
            final_data[key] = value.copy() 
    
    # locationsã‚‚æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ  (locationsè‡ªä½“ã¯å¤§é‡ã ãŒã€ã“ã“ã§ã¯ã‚³ãƒ”ãƒ¼ã‚’è¨±å®¹)
    final_data["locations"] = locations.copy()
    
    # 4. ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚ŒãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®NumPyé…åˆ—ã‚’äº‹å‰ã«ç¢ºä¿ (ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆ)
    # å½¢çŠ¶ã¯ (N, H, W, 2) ã«ãªã‚Šã¾ã™ï¼ˆç”»åƒ(1ch) + å£(1ch)ï¼‰
    observations = np.empty((num_locations, H, W, 2), dtype=np.float32) 
    
    print(f"ğŸ’¾ å‡ºåŠ›é…åˆ—ã‚’ãƒ¡ãƒ¢ãƒªã«äº‹å‰ç¢ºä¿ä¸­... ã‚µã‚¤ã‚º: {observations.nbytes / 1024**3:.2f} GB")


    # 5. ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’ãƒãƒƒãƒã”ã¨ã«è¡Œã„ã€äº‹å‰ã«ç¢ºä¿ã—ãŸé…åˆ—ã«ç›´æ¥æ›¸ãè¾¼ã‚€
    for i in tqdm(range(0, num_locations, args.render_batch_size), desc="Rendering Batches"):
        sl = slice(i, min(i + args.render_batch_size, num_locations))
        traj_slice = locations[sl]
        
        # 1. ç”»åƒã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        # images_tensor ã®å½¢çŠ¶: (batch_size, H, W)
        images_tensor = ds.render_location(torch.from_numpy(traj_slice))

        # 2. Wallæƒ…å ±ã®ä»˜ä¸
        batch_size = images_tensor.shape[0] # <--- ç¾åœ¨ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å–å¾— (ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ)
        
        # walls_numpyã‚’PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«æˆ»ã—ã€ãƒãƒƒãƒæ¬¡å…ƒ(æ¬¡å…ƒ0)ã‚’è¿½åŠ ã—ã¦ (1, H, W, 1) ã«ã™ã‚‹
        walls_batch_dim = torch.from_numpy(walls_numpy).unsqueeze(0) 

        # ãƒãƒƒãƒæ¬¡å…ƒã§ç¾åœ¨ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ãƒªãƒ”ãƒ¼ãƒˆã—ã€å½¢çŠ¶ã‚’ (batch_size, H, W, 1) ã«ã™ã‚‹
        repeated_walls = walls_batch_dim.repeat(batch_size, 1, 1, 1)

        # 3. ç”»åƒã¨å£ã‚’çµåˆ
        # images_tensor ã®å½¢çŠ¶ã‚’ (batch_size, H, W, 1) ã«ã™ã‚‹
        images_tensor = images_tensor.unsqueeze(-1)
        
        # dim=-1 (æ¬¡å…ƒ3, ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒ) ã§çµåˆ -> (batch_size, H, W, 2)
        combined_images = torch.cat([images_tensor, repeated_walls], dim=-1)

        # 4. NumPyé…åˆ—ã«å¤‰æ›ã—ã€äº‹å‰ã«ç¢ºä¿ã—ãŸobservationsé…åˆ—ã®å¯¾å¿œã™ã‚‹ã‚¹ãƒ©ã‚¤ã‚¹ã«æ›¸ãè¾¼ã‚€
        observations[sl] = combined_images.numpy()

    # 6. æœ€çµ‚çš„ãªè¾æ›¸ã«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµæœã‚’è¿½åŠ 
    final_data["observations"] = observations
    final_data["walls"] = walls_numpy # Wallæƒ…å ±ã‚‚åˆ¥é€”ä¿å­˜

    # 7. ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ä¿å­˜
    print(f"ğŸ‰ å‡¦ç†å®Œäº†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ {args.output_path} ã«ä¿å­˜ã—ã¾ã™...")
    np.savez(args.output_path, **final_data)


if __name__ == "__main__":
    main()
